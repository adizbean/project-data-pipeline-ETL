# Project Data Pipeline-ETL
## Project Overview
This project aims to build a data pipeline that includes web scraping and ETL (Extract, Transform, Load) processes. The data is collected from the Tinkerlust e-commerce website using BeautifulSoup, a Python library used to automatically extract data from web pages.

Once the data is collected, the ETL process consists of:

- Extract: Scraping product data from the Tinkerlust website.
- Transform: Cleaning and formatting the data using Python to prepare it for analysis.
- Load: Storing the processed data into a PostgreSQL database for further analysis.

This pipeline is designed to streamline the collection and processing of data efficiently and can be automated for regular updates.

## Data Source
The data was scraped from: https://www.tinkerlust.com/wanita/tas

## Tools & Libraries
![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white)  
![Pandas](https://img.shields.io/badge/Pandas-150458?style=for-the-badge&logo=pandas&logoColor=white)  
![BeautifulSoup](https://img.shields.io/badge/BeautifulSoup-4B0082?style=for-the-badge&logo=beautifulsoup&logoColor=white)
![Selenium](https://img.shields.io/badge/Selenium-43B02A?style=for-the-badge&logo=selenium&logoColor=white)
![SQL](https://img.shields.io/badge/SQL-336791?style=for-the-badge&logo=postgresql&logoColor=white)

